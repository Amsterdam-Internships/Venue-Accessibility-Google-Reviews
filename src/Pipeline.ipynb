{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mylene/opt/anaconda3/envs/BachelorsProject/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-02-28 12:27:41.820858: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # for data pre-processing\n",
    "import seaborn as sns # for visualisations\n",
    "import matplotlib.pyplot as plt # for creating graphs\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_curve, auc, balanced_accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import transformers\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "## add this to the bottom of the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mylene/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/mylene/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/mylene/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# NLTK\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "# stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda list --export > requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_path = \"/Users/mylene/BachelorsProject/Venue-Accessibility-Google-Reviews/GoogleReviews\"\n",
    "training_file_path = \"/Users/mylene/BachelorsProject/Venue-Accessibility-Google-Reviews/Euan's Guide Data.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_file_names = glob.glob(test_file_path + \"/*.csv\")\n",
    "\n",
    "google_df = []\n",
    "\n",
    "for file_name in all_file_names:\n",
    "    df = pd.read_csv(file_name, index_col=None, header=0)\n",
    "    google_df.append(df)\n",
    "\n",
    "test_data = pd.concat(google_df, axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_excel(training_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Venue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Overview</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Dobbies garden center has a large range of ite...</td>\n",
       "      <td>Perth</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>https:||www.euansguide.com|venues|dobbies-gard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transport &amp; Parking</td>\n",
       "      <td>5.0</td>\n",
       "      <td>There is disabled parking close to the doors, ...</td>\n",
       "      <td>Perth</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>https:||www.euansguide.com|venues|dobbies-gard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Access</td>\n",
       "      <td>5.0</td>\n",
       "      <td>There is a lift and there is also a cafe where...</td>\n",
       "      <td>Perth</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>https:||www.euansguide.com|venues|dobbies-gard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toilets</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Perth</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>https:||www.euansguide.com|venues|dobbies-gard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Staff</td>\n",
       "      <td>3.5</td>\n",
       "      <td>There were some staff who were very helpful an...</td>\n",
       "      <td>Perth</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>https:||www.euansguide.com|venues|dobbies-gard...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Aspect  Rating  \\\n",
       "0             Overview     5.0   \n",
       "1  Transport & Parking     5.0   \n",
       "2               Access     5.0   \n",
       "3              Toilets     0.0   \n",
       "4                Staff     3.5   \n",
       "\n",
       "                                              Review    City  \\\n",
       "0  Dobbies garden center has a large range of ite...   Perth   \n",
       "1  There is disabled parking close to the doors, ...   Perth   \n",
       "2  There is a lift and there is also a cafe where...   Perth   \n",
       "3                                                NaN   Perth   \n",
       "4  There were some staff who were very helpful an...   Perth   \n",
       "\n",
       "            Country                                              Venue  \n",
       "0   United Kingdom   https:||www.euansguide.com|venues|dobbies-gard...  \n",
       "1   United Kingdom   https:||www.euansguide.com|venues|dobbies-gard...  \n",
       "2   United Kingdom   https:||www.euansguide.com|venues|dobbies-gard...  \n",
       "3   United Kingdom   https:||www.euansguide.com|venues|dobbies-gard...  \n",
       "4   United Kingdom   https:||www.euansguide.com|venues|dobbies-gard...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Name</th>\n",
       "      <th>Review Rate</th>\n",
       "      <th>Review Time</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>name</th>\n",
       "      <th>street</th>\n",
       "      <th>housenumber</th>\n",
       "      <th>city</th>\n",
       "      <th>postcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>RD_x</th>\n",
       "      <th>RD_y</th>\n",
       "      <th>tile_code</th>\n",
       "      <th>place_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Ellis</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>3 years ago</td>\n",
       "      <td>It was a bit quite when we went in, but don’t ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Ellis</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>2 years ago</td>\n",
       "      <td>Nice cozy place which serves very tasty burger...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Ellis</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>3 years ago</td>\n",
       "      <td>Really nice place. One of my favourite burger ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Ellis</td>\n",
       "      <td>2 stars</td>\n",
       "      <td>3 years ago</td>\n",
       "      <td>The Service was quite good but the burgers we ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Ellis</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>2 years ago</td>\n",
       "      <td>I had a very nice experience! The staff were r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   Name Review Rate  Review Time  \\\n",
       "0         0.0  Ellis    5 stars   3 years ago   \n",
       "1         1.0  Ellis    5 stars   2 years ago   \n",
       "2         2.0  Ellis    5 stars   3 years ago   \n",
       "3         3.0  Ellis    2 stars   3 years ago   \n",
       "4         4.0  Ellis    5 stars   2 years ago   \n",
       "\n",
       "                                         Review Text name street housenumber  \\\n",
       "0  It was a bit quite when we went in, but don’t ...  NaN    NaN         NaN   \n",
       "1  Nice cozy place which serves very tasty burger...  NaN    NaN         NaN   \n",
       "2  Really nice place. One of my favourite burger ...  NaN    NaN         NaN   \n",
       "3  The Service was quite good but the burgers we ...  NaN    NaN         NaN   \n",
       "4  I had a very nice experience! The staff were r...  NaN    NaN         NaN   \n",
       "\n",
       "  city postcode  lat  lon  RD_x  RD_y tile_code place_id  \n",
       "0  NaN      NaN  NaN  NaN   NaN   NaN       NaN      NaN  \n",
       "1  NaN      NaN  NaN  NaN   NaN   NaN       NaN      NaN  \n",
       "2  NaN      NaN  NaN  NaN   NaN   NaN       NaN      NaN  \n",
       "3  NaN      NaN  NaN  NaN   NaN   NaN       NaN      NaN  \n",
       "4  NaN      NaN  NaN  NaN   NaN   NaN       NaN      NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move this to pre-processing script\n",
    "def cleaning_test_df(df):\n",
    "    \n",
    "    # Rename and drop colums\n",
    "    df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "    df = df.drop(columns=[\"Review Time\"])\n",
    "    df = df.rename(columns={\"Review Text\": \"Text\", \"Review Rate\": \"Sentiment\"})\n",
    "\n",
    "    # Drop NaN\n",
    "    df = df[df[\"Text\"].notna()]\n",
    "    df[\"Text\"] = df[\"Text\"].apply(lambda x: x.replace(\"\\n\", ' '))\n",
    "\n",
    "    # Drop reviews with a rating of 0 (rating is missing)\n",
    "    df = df[df[\"Sentiment\"]!=\"0 stars\"]\n",
    "    \n",
    "    for col in df.columns:\n",
    "    # Check if the column has all NaN values\n",
    "        if df[col].isnull().all():\n",
    "            # Drop the column\n",
    "            df.drop(col, axis=1, inplace=True)\n",
    "\n",
    "    # Tokenize into sentences: regEX\n",
    "    rule = r\"(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s\"\n",
    "    df[\"Text\"] = df[\"Text\"].apply(lambda x: re.split(rule, x))\n",
    "    df = df.explode(\"Text\", ignore_index=True)\n",
    "    df = df[df[\"Text\"].notna()]\n",
    "    df = df[df['Text']!='']\n",
    "\n",
    "    df[\"Sentiment\"] = df[\"Sentiment\"].map(lambda x: re.sub(\" stars\", \"\", x))\n",
    "    df[\"Sentiment\"] = df[\"Sentiment\"].map(lambda x: re.sub(\" star\", \"\", x))\n",
    "    df[\"Sentiment\"] = df[\"Sentiment\"].map(lambda x: int(x))\n",
    "\n",
    "    # Rating into Sentiment\n",
    "    df[\"Sentiment\"] = df[\"Sentiment\"].map(lambda score: 'positive' if score > 3 else 'negative')\n",
    "    df['Label'] = df[\"Sentiment\"].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "    print(\"---> DONE CLEANING\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= PRE-PROCESSING FOR MACHINE LEARNING MODELS =========\n",
    "def text_preprocessing(s):\n",
    "    \"\"\"\n",
    "    - Lowercase the sentence\n",
    "    - Remove URLs\n",
    "    - Change \"'t\" to \"not\"\n",
    "    - Isolate and remove punctuations except \"?\"\n",
    "    - Remove other special characters\n",
    "    - Remove stop words except \"not\" and \"can\"\n",
    "    - Remove trailing whitespace\n",
    "    \"\"\"\n",
    "    s = s.lower()\n",
    "    # Remove URLs\n",
    "    s = re.sub(r\"http.*?(?=\\s)\", \"\", s) \n",
    "    # Change 't to 'not'\n",
    "    s = re.sub(r\"\\'t\", \" not\", s)\n",
    "    # Remove @name\n",
    "    s = re.sub(r'(@.*?)[\\s]', ' ', s)\n",
    "    # Isolate and remove punctuations except '?'\n",
    "    s = re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\\\\\/\\,])', r' \\1 ', s)\n",
    "    s = re.sub(r'[^\\w\\s\\?]', ' ', s)\n",
    "    # Remove some special characters\n",
    "    s = re.sub(r'([\\;\\:\\|•«\\n])', ' ', s)\n",
    "    # Remove stopwords except 'not' and 'can'\n",
    "    s = \" \".join([word for word in s.split()\n",
    "                  if word not in stopwords.words('english')\n",
    "                  or word in ['not', 'can']])\n",
    "    # Remove trailing whitespace\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_training_df(df):\n",
    "    # Rename and drop colums\n",
    "    df = df.drop(columns=[\"City\", \"Country\"])\n",
    "    df = df.rename(columns={\"Review\": \"Text\"})\n",
    "\n",
    "    # Drop irrelevant aspects\n",
    "    df = df[df['Aspect']!='Anything else you wish to tell us?']\n",
    "    df = df[df['Aspect']!='Venue Manager responded to this review']       \n",
    "    df = df[df['Aspect']!='COVID Precautions']  \n",
    "    df = df[df['Aspect']!='Accessibility Guide']  \n",
    "    df = df[df['Aspect']!='Awards List'] \n",
    "    df = df[df['Aspect']!='Access Statement']\n",
    "\n",
    "    # Drop NaN\n",
    "    df = df[df[\"Text\"].notna()]\n",
    "\n",
    "    # Some reviews contain: \"A description about the access has not been added for this venue.\"\n",
    "    # These have a rating <=0.0\n",
    "    # Remove no description reviews\n",
    "    df = df[df[\"Rating\"]>0.0]\n",
    "\n",
    "    # Remove review if sentence count == 0\n",
    "    df[\"SentenceCount\"] = df[\"Text\"].apply(lambda x: len(sent_tokenize(x)))\n",
    "    df = df[df[\"SentenceCount\"]!=0]\n",
    "\n",
    "    # Take only the venue name\n",
    "    df[\"Venue\"] = df[\"Venue\"].apply(lambda x: ' '.join(x.split('|')[4].split(\"-\")[:-1]))\n",
    "\n",
    "    # Rating into Sentiment\n",
    "    df[\"Sentiment\"] = df[\"Rating\"].map(lambda score: 'positive' if score > 3.0 else 'negative')\n",
    "    df['Label'] = df[\"Sentiment\"].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "    print(\"---> DONE CLEANING\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> DONE CLEANING\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Text</th>\n",
       "      <th>Venue</th>\n",
       "      <th>SentenceCount</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Overview</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Dobbies garden center has a large range of ite...</td>\n",
       "      <td>dobbies garden centre perth</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transport &amp; Parking</td>\n",
       "      <td>5.0</td>\n",
       "      <td>There is disabled parking close to the doors, ...</td>\n",
       "      <td>dobbies garden centre perth</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Access</td>\n",
       "      <td>5.0</td>\n",
       "      <td>There is a lift and there is also a cafe where...</td>\n",
       "      <td>dobbies garden centre perth</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Staff</td>\n",
       "      <td>3.5</td>\n",
       "      <td>There were some staff who were very helpful an...</td>\n",
       "      <td>dobbies garden centre perth</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Overview</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Fantastic spot with great cocktails, friendly ...</td>\n",
       "      <td>bow lane dublin</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56590</th>\n",
       "      <td>Toilets</td>\n",
       "      <td>3.5</td>\n",
       "      <td>It's on the ground floor, just inside the main...</td>\n",
       "      <td>wien museum karlsplatz vienna</td>\n",
       "      <td>3</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56591</th>\n",
       "      <td>Staff</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Friendly and helpful. One staff member saw us ...</td>\n",
       "      <td>wien museum karlsplatz vienna</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56593</th>\n",
       "      <td>Overview</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Friendly and helpful staff who examined how th...</td>\n",
       "      <td>kirkcudbright swimming pool kirkcudbright</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56594</th>\n",
       "      <td>Transport &amp; Parking</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Spaces located by the door and clearly signed ...</td>\n",
       "      <td>kirkcudbright swimming pool kirkcudbright</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56596</th>\n",
       "      <td>Toilets</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Two large loos. One is also a changing room fi...</td>\n",
       "      <td>kirkcudbright swimming pool kirkcudbright</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40024 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Aspect  Rating  \\\n",
       "0                 Overview     5.0   \n",
       "1      Transport & Parking     5.0   \n",
       "2                   Access     5.0   \n",
       "4                    Staff     3.5   \n",
       "6                 Overview     4.5   \n",
       "...                    ...     ...   \n",
       "56590              Toilets     3.5   \n",
       "56591                Staff     5.0   \n",
       "56593             Overview     5.0   \n",
       "56594  Transport & Parking     5.0   \n",
       "56596              Toilets     5.0   \n",
       "\n",
       "                                                    Text  \\\n",
       "0      Dobbies garden center has a large range of ite...   \n",
       "1      There is disabled parking close to the doors, ...   \n",
       "2      There is a lift and there is also a cafe where...   \n",
       "4      There were some staff who were very helpful an...   \n",
       "6      Fantastic spot with great cocktails, friendly ...   \n",
       "...                                                  ...   \n",
       "56590  It's on the ground floor, just inside the main...   \n",
       "56591  Friendly and helpful. One staff member saw us ...   \n",
       "56593  Friendly and helpful staff who examined how th...   \n",
       "56594  Spaces located by the door and clearly signed ...   \n",
       "56596  Two large loos. One is also a changing room fi...   \n",
       "\n",
       "                                           Venue  SentenceCount Sentiment  \\\n",
       "0                    dobbies garden centre perth              1  positive   \n",
       "1                    dobbies garden centre perth              2  positive   \n",
       "2                    dobbies garden centre perth              2  positive   \n",
       "4                    dobbies garden centre perth              1  positive   \n",
       "6                                bow lane dublin              1  positive   \n",
       "...                                          ...            ...       ...   \n",
       "56590              wien museum karlsplatz vienna              3  positive   \n",
       "56591              wien museum karlsplatz vienna              2  positive   \n",
       "56593  kirkcudbright swimming pool kirkcudbright              2  positive   \n",
       "56594  kirkcudbright swimming pool kirkcudbright              1  positive   \n",
       "56596  kirkcudbright swimming pool kirkcudbright              2  positive   \n",
       "\n",
       "       Label  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "4          1  \n",
       "6          1  \n",
       "...      ...  \n",
       "56590      1  \n",
       "56591      1  \n",
       "56593      1  \n",
       "56594      1  \n",
       "56596      1  \n",
       "\n",
       "[40024 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cleaned_train_data = cleaning_training_df(training_data)\n",
    "display(cleaned_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> DONE CLEANING\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>positive</td>\n",
       "      <td>It was a bit quite when we went in, but don’t ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>positive</td>\n",
       "      <td>Rightfully so! The burgers (and nachos) were l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>positive</td>\n",
       "      <td>I would definitely recommend this place if you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>positive</td>\n",
       "      <td>Nice cozy place which serves very tasty burger...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>positive</td>\n",
       "      <td>They have a good selection of burgers and othe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815766</th>\n",
       "      <td>Amstelhoeck</td>\n",
       "      <td>positive</td>\n",
       "      <td>(Translated by Google) In a word super  (Origi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815767</th>\n",
       "      <td>Amstelhoeck</td>\n",
       "      <td>negative</td>\n",
       "      <td>(Translated by Google) Recommended  (Original)...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815768</th>\n",
       "      <td>Amstelhoeck</td>\n",
       "      <td>positive</td>\n",
       "      <td>(Translated by Google) Location location locat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815769</th>\n",
       "      <td>Amstelhoeck</td>\n",
       "      <td>negative</td>\n",
       "      <td>(Translated by Google) Nice moment  (Original)...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815770</th>\n",
       "      <td>Amstelhoeck</td>\n",
       "      <td>positive</td>\n",
       "      <td>(Translated by Google) Cozy  (Original) Aconch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>815771 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name Sentiment  \\\n",
       "0             Ellis  positive   \n",
       "1             Ellis  positive   \n",
       "2             Ellis  positive   \n",
       "3             Ellis  positive   \n",
       "4             Ellis  positive   \n",
       "...             ...       ...   \n",
       "815766  Amstelhoeck  positive   \n",
       "815767  Amstelhoeck  negative   \n",
       "815768  Amstelhoeck  positive   \n",
       "815769  Amstelhoeck  negative   \n",
       "815770  Amstelhoeck  positive   \n",
       "\n",
       "                                                     Text  Label  \n",
       "0       It was a bit quite when we went in, but don’t ...      1  \n",
       "1       Rightfully so! The burgers (and nachos) were l...      1  \n",
       "2       I would definitely recommend this place if you...      1  \n",
       "3       Nice cozy place which serves very tasty burger...      1  \n",
       "4       They have a good selection of burgers and othe...      1  \n",
       "...                                                   ...    ...  \n",
       "815766  (Translated by Google) In a word super  (Origi...      1  \n",
       "815767  (Translated by Google) Recommended  (Original)...      0  \n",
       "815768  (Translated by Google) Location location locat...      1  \n",
       "815769  (Translated by Google) Nice moment  (Original)...      0  \n",
       "815770  (Translated by Google) Cozy  (Original) Aconch...      1  \n",
       "\n",
       "[815771 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cleaned_test_data = cleaning_test_df(test_data)\n",
    "display(cleaned_test_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data  40024\n",
      "test data  815771\n"
     ]
    }
   ],
   "source": [
    "shuffled_training_data = cleaned_train_data.sample(frac=1)\n",
    "print(\"training data \", shuffled_training_data.shape[0])\n",
    "shuffled_test_data = cleaned_test_data.sample(frac=1)\n",
    "print(\"test data \", shuffled_test_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 20% Training %80 \n",
    "shuffled_training_data = shuffled_training_data[:32019]\n",
    "shuffled_test_data = shuffled_test_data[:8005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = shuffled_training_data.Text.values\n",
    "y = shuffled_training_data.Label.values\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_path = \"/Users/mylene/BachelorsProject/Venue-Accessibility-Google-Reviews/src/data/\"\n",
    "shuffled_training_data.to_csv(save_to_path+'train_data.csv')\n",
    "shuffled_test_data.to_csv(save_to_path+'test_data.csv')\n",
    "pd.DataFrame(X_train).to_csv(save_to_path+'X_train.csv')\n",
    "pd.DataFrame(X_val).to_csv(save_to_path+'X_val.csv')\n",
    "pd.DataFrame(y_train).to_csv(save_to_path+'y_train.csv')\n",
    "pd.DataFrame(y_val).to_csv(save_to_path+'y_val.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== TOKENIZE WITH BERT =========\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "labels = {'Toilets':0, 'Overview':1, 'Staff':2, 'Transport & Parking':3, 'Access':4}\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.Target = [labels[label] for label in df['Aspect']]\n",
    "        self.texts = [tokenizer(text, \n",
    "                               padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['Text']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.Target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Target)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.Target[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== BERT CLASSIFIER CLASS =========\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== BERT TRAINING =========\n",
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=16, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=16)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "                print(output)\n",
    "                batch_loss = criterion(output, train_label)\n",
    "                total_loss_train += batch_loss.item()\n",
    "                print(batch_loss)\n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "                print(\"out\")\n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label)\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            print(\n",
    "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
    "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
    "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
    "                | Val Accuracy: {total_acc_val / len(val_data): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_data):\n",
    "    output_lst = []\n",
    "    test_label_lst = []\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "              test_label = test_label.to(device)\n",
    "              mask = test_input['attention_mask'].to(device)\n",
    "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "              test_label_lst.append(test_label)\n",
    "\n",
    "              output = model(input_id, mask)\n",
    "              output_lst.append(output.argmax(dim=1))\n",
    "\n",
    "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "              total_acc_test += acc\n",
    "    \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
    "\n",
    "    accuracy = total_acc_test / len(test_data)\n",
    "\n",
    "    return accuracy, output_lst, test_label_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "boundary_val = round(cleaned_train_data.shape[0] * 0.8)\n",
    "train_data_c = cleaned_train_data[:boundary_val]\n",
    "val_data_c = cleaned_train_data[boundary_val:]\n",
    "              \n",
    "train(model, train_data_c, val_data_c, LR, EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"/Users/mylene/BachelorsProject/Venue-Accessibility-Google-Reviews/src/Results\"\n",
    "boundary_val_2 = round(cleaned_test_data.shape[0]*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, output_lst, test_label_lst = evaluate(model, cleaned_test_data[:boundary_val_2])\n",
    "df_output = pd.DataFrame(output_lst)\n",
    "df_output.to_csv(results_path+\"target_pred_bert_fine-tuned.csv\")\n",
    "\n",
    "test_label = pd.DataFrame(test_label_lst)\n",
    "test_label.to_csv(results_path+\"target_pred_bert_fine-tuned.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BachelorsProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "ce9b574a48ef7c03a00e54e295c4e0f81aff6cb0c102e1aab84b271b5721331b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

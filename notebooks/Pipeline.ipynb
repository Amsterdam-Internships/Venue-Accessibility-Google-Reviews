{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading files and Environment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will be separated out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%conda env export > environment.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import pathlib\n",
    "import sklearn\n",
    "import numpy\n",
    "import nltk\n",
    "import wordcloud\n",
    "import gensim\n",
    "import scipy.stats as stats\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import load_iris\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current directory\n",
    "current_dir = os.getcwd()\n",
    "# Get parent directory\n",
    "parent_dir = os.path.join(current_dir, '..')\n",
    "# Append parent directory to sys.path\n",
    "sys.path.append(parent_dir)\n",
    "from src import data_cleaning as dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: /Users/mylene/BachelorsProject/Venue-Accessibility-Google-Reviews/datasets/EuansGuideData.xlsx\n",
      "path: /Users/mylene/BachelorsProject/Venue-Accessibility-Google-Reviews/datasets/GoogleReviews\n"
     ]
    }
   ],
   "source": [
    "cwd = pathlib.Path.cwd().parent\n",
    "training_file_path = cwd.joinpath(\"datasets/EuansGuideData.xlsx\")\n",
    "test_file_path = cwd.joinpath(\"datasets/GoogleReviews\")\n",
    "print('path:', training_file_path)\n",
    "print('path:', test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_file_names = glob.glob(str(test_file_path) + \"/*.csv\")\n",
    "google_df = [pd.read_csv(file_name, index_col=None, header=0) for file_name in all_file_names]\n",
    "test_data = pd.concat(google_df, axis=0, ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mylene/BachelorsProject/Venue-Accessibility-Google-Reviews/notebooks/../src/data_cleaning.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Text\"] = df[\"Text\"].apply(lambda x: x.replace(\"\\n\", ' '))\n",
      "/Users/mylene/BachelorsProject/Venue-Accessibility-Google-Reviews/notebooks/../src/data_cleaning.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_aspects[\"Venue\"] = selected_aspects[\"Venue\"].apply(lambda x: get_venue_name(x))\n",
      "/Users/mylene/BachelorsProject/Venue-Accessibility-Google-Reviews/notebooks/../src/data_cleaning.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Sentiment\"] = df[\"Rating\"].apply(lambda x : pick_sentiment(x))\n",
      "/Users/mylene/BachelorsProject/Venue-Accessibility-Google-Reviews/notebooks/../src/data_cleaning.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Label'] = df[\"Sentiment\"].map({'positive': 1, 'negative': 0})\n"
     ]
    }
   ],
   "source": [
    "training_data = pd.read_excel(training_file_path)\n",
    "clean_train_df = dc.clean_and_select(training_data, [\"Aspect\", \"Rating\", \"Review\", \"Venue\"])\n",
    "clean_test_df = dc.clean_and_select(test_data, [\"Name\",\"Review Rate\", \"Review Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "translator = str.maketrans('', '', string.punctuation+'\\u2026')\n",
    "\n",
    "def remove_small_words(sentence):\n",
    "   \n",
    "    if len(nltk.word_tokenize(sentence.translate(translator))) >= 5:\n",
    "       return sentence\n",
    "    else:\n",
    "       return \"useless\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pattern = r'\\(Translated by Google\\)|\\(Original\\)'  # Define the regular expression pattern\n",
    "clean_test_df['Text'] = clean_test_df['Text'].str.replace(pattern, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>House of Watt</td>\n",
       "      <td>negative</td>\n",
       "      <td>nowadays no coffee workplace but you can only...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>House of Watt</td>\n",
       "      <td>negative</td>\n",
       "      <td>Nicely dressed, but the prices are high, I ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>House of Watt</td>\n",
       "      <td>positive</td>\n",
       "      <td>Hidden gem; delicious brisket burgers, cozy a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>House of Watt</td>\n",
       "      <td>positive</td>\n",
       "      <td>House of Watt is close to the Amstel station....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>House of Watt</td>\n",
       "      <td>positive</td>\n",
       "      <td>Super place to watch Ajax (during corona). Go...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name Sentiment  \\\n",
       "792  House of Watt  negative   \n",
       "793  House of Watt  negative   \n",
       "794  House of Watt  positive   \n",
       "795  House of Watt  positive   \n",
       "796  House of Watt  positive   \n",
       "\n",
       "                                                  Text  Label  \n",
       "792   nowadays no coffee workplace but you can only...      0  \n",
       "793   Nicely dressed, but the prices are high, I ha...      0  \n",
       "794   Hidden gem; delicious brisket burgers, cozy a...      1  \n",
       "795   House of Watt is close to the Amstel station....      1  \n",
       "796   Super place to watch Ajax (during corona). Go...      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test_df[400:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>positive</td>\n",
       "      <td>It was a bit quite when we went in, but don’t ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[It was a bit quite when we went in, but don’t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>positive</td>\n",
       "      <td>Nice cozy place which serves very tasty burger...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Nice cozy place which serves very tasty burge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>positive</td>\n",
       "      <td>Really nice place. One of my favourite burger ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Really nice place., One of my favourite burge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>negative</td>\n",
       "      <td>The Service was quite good but the burgers we ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[The Service was quite good but the burgers we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>positive</td>\n",
       "      <td>I had a very nice experience! The staff were r...</td>\n",
       "      <td>1</td>\n",
       "      <td>[I had a very nice experience!, The staff were...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name Sentiment                                               Text  Label  \\\n",
       "0  Ellis  positive  It was a bit quite when we went in, but don’t ...      1   \n",
       "1  Ellis  positive  Nice cozy place which serves very tasty burger...      1   \n",
       "2  Ellis  positive  Really nice place. One of my favourite burger ...      1   \n",
       "3  Ellis  negative  The Service was quite good but the burgers we ...      0   \n",
       "4  Ellis  positive  I had a very nice experience! The staff were r...      1   \n",
       "\n",
       "                                                text  \n",
       "0  [It was a bit quite when we went in, but don’t...  \n",
       "1  [Nice cozy place which serves very tasty burge...  \n",
       "2  [Really nice place., One of my favourite burge...  \n",
       "3  [The Service was quite good but the burgers we...  \n",
       "4  [I had a very nice experience!, The staff were...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = clean_test_df.assign(text=clean_test_df['Text'].apply(nltk.sent_tokenize)).explode('Text').reset_index(drop=True)\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>positive</td>\n",
       "      <td>It was a bit quite when we went in, but don’t ...</td>\n",
       "      <td>1</td>\n",
       "      <td>It was a bit quite when we went in, but don’t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>positive</td>\n",
       "      <td>It was a bit quite when we went in, but don’t ...</td>\n",
       "      <td>1</td>\n",
       "      <td>After a little while the place was cozily busy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>positive</td>\n",
       "      <td>It was a bit quite when we went in, but don’t ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Rightfully so!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>positive</td>\n",
       "      <td>It was a bit quite when we went in, but don’t ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The burgers (and nachos) were lovely, as was t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>positive</td>\n",
       "      <td>It was a bit quite when we went in, but don’t ...</td>\n",
       "      <td>1</td>\n",
       "      <td>I would definitely recommend this place if you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name Sentiment                                               Text  Label  \\\n",
       "0  Ellis  positive  It was a bit quite when we went in, but don’t ...      1   \n",
       "1  Ellis  positive  It was a bit quite when we went in, but don’t ...      1   \n",
       "2  Ellis  positive  It was a bit quite when we went in, but don’t ...      1   \n",
       "3  Ellis  positive  It was a bit quite when we went in, but don’t ...      1   \n",
       "4  Ellis  positive  It was a bit quite when we went in, but don’t ...      1   \n",
       "\n",
       "                                                text  \n",
       "0  It was a bit quite when we went in, but don’t ...  \n",
       "1    After a little while the place was cozily busy.  \n",
       "2                                     Rightfully so!  \n",
       "3  The burgers (and nachos) were lovely, as was t...  \n",
       "4  I would definitely recommend this place if you...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = sample_df.explode('text').reset_index(drop=True)\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>It was a bit quite when we went in, but don’t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>After a little while the place was cozily busy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>Rightfully so!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>The burgers (and nachos) were lovely, as was t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>I would definitely recommend this place if you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name Sentiment  Label                                               text\n",
       "0  Ellis  positive      1  It was a bit quite when we went in, but don’t ...\n",
       "1  Ellis  positive      1    After a little while the place was cozily busy.\n",
       "2  Ellis  positive      1                                     Rightfully so!\n",
       "3  Ellis  positive      1  The burgers (and nachos) were lovely, as was t...\n",
       "4  Ellis  positive      1  I would definitely recommend this place if you..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = sample_df.drop('Text', axis=1)\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['text'] = sample_df['text'].apply(remove_small_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>It was a bit quite when we went in, but don’t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>After a little while the place was cozily busy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>useless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>The burgers (and nachos) were lovely, as was t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>I would definitely recommend this place if you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name Sentiment  Label                                               text\n",
       "0  Ellis  positive      1  It was a bit quite when we went in, but don’t ...\n",
       "1  Ellis  positive      1    After a little while the place was cozily busy.\n",
       "2  Ellis  positive      1                                            useless\n",
       "3  Ellis  positive      1  The burgers (and nachos) were lovely, as was t...\n",
       "4  Ellis  positive      1  I would definitely recommend this place if you..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = sample_df[sample_df['text'].str.contains(\"useless\") == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_pattern = r\".*([Pp]ancakes|[Dd]rink|[Dd]esserts|[Gg]in|[Ww]ine|[Bb]reakfast|[Ll]unch|[Pp]asta|[Vv]egeterian|[Vv]egan|[Bb]urgers|[Pp]asta|[Dd]ish|[Bb]eer|[Pp]izza|[Tt]aste|[Ff]ood|[Cc]ocktail|[Cc]offee|[Mm]enu|[Tt]asty|[Dd]elicious|[Ss]taff|[Hh]ost|[Aa]mbience|[Aa]tmosphere|[Cc]o[sz]y|[Gg]ezellig|[Ss]ervice]|[Pp]rice[y]|[Cc]heap|([Nn]ice|[Gg]reat|[Aa]mazing) place|([Gg]ood|[Bb]ad|[Tt]errible|[Gg]reat) experience).*\"\n",
    "\n",
    "mask = sample_df['text'].str.contains(reg_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = sample_df[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>It was a bit quite when we went in, but don’t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>After a little while the place was cozily busy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>I would definitely recommend this place if you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>The best thing is you can even get a gluten-fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>One of my favourite burger joints whole visiti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name Sentiment  Label                                               text\n",
       "0   Ellis  positive      1  It was a bit quite when we went in, but don’t ...\n",
       "1   Ellis  positive      1    After a little while the place was cozily busy.\n",
       "4   Ellis  positive      1  I would definitely recommend this place if you...\n",
       "8   Ellis  positive      1  The best thing is you can even get a gluten-fr...\n",
       "11  Ellis  positive      1  One of my favourite burger joints whole visiti..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import wordnet as wn\n",
    "\n",
    "# # define a function to check if a word is related to food or drink\n",
    "# def is_food_or_drink(word):\n",
    "#     food_synsets = wn.synsets('food')\n",
    "#     drink_synsets = wn.synsets('drink')\n",
    "#     food_and_drink_words = set()\n",
    "#     for synset in food_synsets + drink_synsets:\n",
    "#         for lemma in synset.lemmas():\n",
    "#             food_and_drink_words.add(lemma.name())\n",
    "#     other_food_and_drink_words = {'breakfast', 'lunch', 'dinner', 'alcohol'}\n",
    "#     food_and_drink_words |= other_food_and_drink_words\n",
    "#     return word in food_and_drink_words\n",
    "\n",
    "# # identify the rows that contain food or drink related words\n",
    "# food_rows = []\n",
    "# for i, row in sample_df.iterrows():\n",
    "#     for word in nltk.word_tokenize(row['text']):\n",
    "#         if is_food_or_drink(word):\n",
    "#             food_rows.append(i)\n",
    "\n",
    "# # drop the rows that contain food or drink related words\n",
    "# sample_df.drop(food_rows, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_random_sample = sample_df.sample(frac=0.02, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2764\n"
     ]
    }
   ],
   "source": [
    "print((google_random_sample).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_random_sample.to_excel('/Users/mylene/BachelorsProject/Venue-Accessibility-Google-Reviews/datasets/labelling data/improved2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_excel('/Users/mylene/BachelorsProject/Venue-Accessibility-Google-Reviews/datasets/11random_google_reviews_excel.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1937 rows that mention the search terms.\n"
     ]
    }
   ],
   "source": [
    "# Assuming your dataframe is named df\n",
    "search_terms = ['Parking', 'Transport', 'Toilets', 'Access', 'Entrance', 'Accessibility', 'Wheelchair', 'Staff']\n",
    "num_rows = sample_df[sample_df['text'].str.contains('|'.join(search_terms), case=False, na=False)].shape[0]\n",
    "print(f\"There are {num_rows} rows that mention the search terms.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(background_color='white', max_words=1000, contour_width=3, contour_color='steeleblue')\n",
    "\n",
    "clustered_reviews_train = ','.join(list(clean_train_df['Text'].values))\n",
    "clustered_reviews_test = ','.join(list(clean_test_df['Text'].values))\n",
    "wordcloud.generate(clustered_reviews_train)\n",
    "wordcloud.generate(clustered_reviews_test)\n",
    "wordcloud.to_image()\n",
    "wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_per_aspect = clean_train_df.groupby(['Aspect']).count()\n",
    "amount_per_aspect = amount_per_aspect['Text']\n",
    "amount_per_aspect.plot(kind='bar', title=\"Overview of Aspects in Euan's Guide data\", ylabel='Amount of aspects', xlabel='Aspect Types', figsize=(6,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_per_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_per_sentiment = clean_train_df.groupby(['Sentiment']).count()\n",
    "amount_per_sentiment = amount_per_sentiment['Text']\n",
    "amount_per_sentiment.plot(kind='bar', title=\"Overview of Sentiments in Euan's Guide data\", ylabel='Amount of Each Sentiment', xlabel='Sentiment Types', figsize=(6,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_per_sentiment "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aspect Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "n = round(len(clean_train_df))\n",
    "euans_reviews = clean_train_df.Text.values.tolist()\n",
    "google_reviews = clean_test_df[:n].Text.values.tolist()\n",
    "euans_labels = clean_train_df.Aspect.values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('clf', VotingClassifier([\n",
    "        ('nb', MultinomialNB()),\n",
    "        ('lr', LogisticRegression())\n",
    "    ]))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vectorizer__max_df': (0.5, 0.75, 1.0),\n",
    "    'vectorizer__ngram_range': ((1, 1), (1, 2)),\n",
    "    'clf__voting': ('soft', 'hard'),\n",
    "    'clf__nb__alpha': (0.5, 1),\n",
    "    'clf__lr__C': (0.1, 1, 10),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=parameters, cv=5, n_jobs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(euans_reviews, euans_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "google_sample = random.sample(google_reviews, len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict(X_val)\n",
    "print(len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_pred = grid_search.predict(google_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_labels = ['Toilets', 'Transport & Parking']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuation_report = classification_report(y_val, y_pred, labels=pos_labels)\n",
    "evaluation_report = classification_report(y_val, google_pred, labels=pos_labels)\n",
    "print(\"Euan's Guide Evaluation Report\\n\",valuation_report)\n",
    "print(\"Google Reviews Evaluation Report\\n\",evaluation_report)\n",
    "# save report as a text file\n",
    "with open('../Results/google_aspect_classification_report.txt', 'w') as f:\n",
    "    f.write(evaluation_report)\n",
    "    \n",
    "with open('../Results/euans_aspect_classification_report.txt', 'w') as f:\n",
    "    f.write(valuation_report)\n",
    "\n",
    "# # convert text file to PNG image\n",
    "img = Image.new('RGB', (800, 800), color='white')\n",
    "font = ImageFont.truetype('../media/Fonts/Roboto/Roboto-Black.ttf', 20)\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "with open('../Results/google_aspect_classification_report.txt', 'r') as f:\n",
    "    y = 0\n",
    "    for line in f.readlines():\n",
    "        draw.text((10, y), line, fill='black', font=font)\n",
    "        y += 20\n",
    "\n",
    "img.save('../Results/google_aspect_classification_report.png')\n",
    "\n",
    "with open('../Results/euans_aspect_classification_report.txt', 'r') as f:\n",
    "    y = 0\n",
    "    for line in f.readlines():\n",
    "        draw.text((10, y), line, fill='black', font=font)\n",
    "        y += 20\n",
    "\n",
    "img.save('../Results/euans_aspect_classification_report.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_val, google_pred)\n",
    "\n",
    "display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=pos_labels)\n",
    "\n",
    "display.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_labels = clean_train_df.Sentiment.values.tolist()\n",
    "X2_train, X2_val, y2_train, y2_val = train_test_split(euans_reviews, sentiment_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "pipeline2 = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('clf', VotingClassifier([\n",
    "        ('nb', MultinomialNB()),\n",
    "        ('svm', SVC())\n",
    "    ]))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_params = {\n",
    "    'vectorizer__max_features': [1000, 5000],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "    'clf__voting': ['hard', 'soft'],\n",
    "    'clf__weights': [[0.5, 0.5], [0.7, 0.3]],\n",
    "    'clf__estimators': [\n",
    "        [('nb', MultinomialNB(alpha=0.5)), ('svm', SVC(kernel='linear', C=1.0))],\n",
    "        [('nb', MultinomialNB(alpha=1.0)), ('svm', SVC(kernel='rbf', C=10.0, gamma=0.1))]\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search2 = GridSearchCV(estimator=pipeline2, param_grid=sentiment_params, cv=5, n_jobs=5, verbose=1)\n",
    "grid_search2.fit(X2_train, y2_train)\n",
    "y2_pred = grid_search2.predict(X2_val)\n",
    "google2_pred = grid_search2.predict(google_sample)\n",
    "euans_report = classification_report(y2_val, y2_pred)\n",
    "google_report = classification_report(google2_pred, y2_pred)\n",
    "\n",
    "print('Euans Report\\n', euans_report)\n",
    "print('Google Report\\n', google_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save report as a text file\n",
    "with open('../Results/google_sentiment_analysis_report.txt', 'w') as f:\n",
    "    f.write(google_report)\n",
    "    \n",
    "with open('../Results/euans_sentiment_analysis_report.txt', 'w') as f:\n",
    "    f.write(euans_report)\n",
    "\n",
    "# # convert text file to PNG image optimise this as you repeat this code.\n",
    "img = Image.new('RGB', (800, 800), color='white')\n",
    "font = ImageFont.truetype('../media/Fonts/Roboto/Roboto-Black.ttf', 20)\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "with open('../Results/euans_sentiment_analysis_report.txt', 'r') as f:\n",
    "    y = 0\n",
    "    for line in f.readlines():\n",
    "        draw.text((10, y), line, fill='black', font=font)\n",
    "        y += 20\n",
    "\n",
    "img.save('../Results/euans_sentiment_analysis_report.png')\n",
    "\n",
    "with open('../Results/google_sentiment_analysis_report.txt', 'r') as f:\n",
    "    y = 0\n",
    "    for line in f.readlines():\n",
    "        draw.text((10, y), line, fill='black', font=font)\n",
    "        y += 20\n",
    "\n",
    "img.save('../Results/google_sentiment_analysis_report.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm2 = confusion_matrix(y2_val, google2_pred)\n",
    "\n",
    "display2 = ConfusionMatrixDisplay(confusion_matrix=cm2, display_labels=pos_labels)\n",
    "\n",
    "display2.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opinion Summarisation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moved this part to Google Colab https://colab.research.google.com/drive/1NVzQ3vS6oaQ7EPFzzij1XbjDQT0QpOBO?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_test_df.to_csv('/Users/mylene/BachelorsProject/Venue-Accessibility-Google-Reviews/datasets/google_reviews.csv', index=False)\n",
    "#clean_train_df.to_csv(\"/Users/mylene/BachelorsProject/Venue-Accessibility-Google-Reviews/datasets/euans_reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "# from textblob import TextBlob\n",
    "# summariser = pipeline('summarization', model='distilbert-base-uncased')\n",
    "\n",
    "# \"\"\"\n",
    "# We want the review text per venue, aspect and sentiment.\n",
    "# \"\"\"\n",
    "# # Possibly vader could look at identifying the sentiment correctly.\n",
    "# # [['Venue', 'Aspect', 'Sentiment', 'Text']]\n",
    "\n",
    "\n",
    "# summaries = summariser(euans_reviews, max_length=50, min_length=10)\n",
    "\n",
    "# reviews_per_venue = clean_train_df['summary'] = [summary['Summarised Review'] for summary in summaries]\n",
    "# reviews_per_venue.head()\n",
    "\n",
    "\n",
    "# # Group all reviews per venue\n",
    "# # generate a summary of the sentiment and aspects for that venue."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lex Rank implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sumy\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "\n",
    "long_reviews = clean_train_df[clean_train_df['SentenceCount'] > 1]\n",
    "long_reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = []\n",
    "i = 0\n",
    "for review in long_reviews.Text.values.tolist():\n",
    "    parser = PlaintextParser.from_string(review,Tokenizer('english'))\n",
    "    i+=1\n",
    "    lex_rank_summarizer = LexRankSummarizer()\n",
    "    summaries.append(lex_rank_summarizer(parser.document, sentences_count=1)) \n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_empty_summary(summary):\n",
    "    if len(summary) == 0:\n",
    "        return \"summary processing error\"\n",
    "    else:\n",
    "        return str(summary[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_reviews['Lex Rank Summary'] = summaries\n",
    "long_reviews['Lex Rank Summary'] = long_reviews['Lex Rank Summary'].apply(lambda x: find_empty_summary(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_reviews['Lex Rank Summary']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Analysis Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "\n",
    "lsa_summarizer=LsaSummarizer()\n",
    "lsa_summaries = []\n",
    "for review in long_reviews.Text.values.tolist():\n",
    "    lsa_parser=PlaintextParser.from_string(review,Tokenizer('english'))\n",
    "    lsa_summaries.append(lsa_summarizer(lsa_parser.document,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_reviews['LSA Summaries'] = lsa_summaries\n",
    "long_reviews['LSA Summaries'] = long_reviews['LSA Summaries'].apply(lambda x: find_empty_summary(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_rank_summaries = long_reviews['Lex Rank Summary'].values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_summaries = long_reviews['LSA Summaries'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_processed = [dc.preprocess(review) for review in lex_rank_summaries]\n",
    "\n",
    "lsa_processed = [dc.preprocess(review) for review in lsa_summaries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "topic_dict = gensim.corpora.Dictionary(lsa_processed)\n",
    "count = 0\n",
    "for k, v in topic_dict.iteritems():\n",
    "    print(k, v)\n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dict.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_corpus = [topic_dict.doc2bow(doc) for doc in lsa_processed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(lsa_corpus)\n",
    "lsa_corpus_tfidf = tfidf[lsa_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(lsa_corpus, num_topics=10, id2word=topic_dict, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(lsa_corpus_tfidf, num_topics=10, id2word=topic_dict, passes=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on google reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test_df['Sentence Count'] = clean_test_df['Text'].apply(lambda x: dc.count_sentences(x))\n",
    "long_google_reviews = clean_test_df[clean_test_df['Sentence Count'] > 1]\n",
    "long_google_reviews = long_google_reviews[:len(y_val)]\n",
    "long_google_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lsa_summary(review):\n",
    "    google_lsa_parser=PlaintextParser.from_string(review,Tokenizer('english'))\n",
    "    return lsa_summarizer(google_lsa_parser.document,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_google_reviews['LSA Summary'] = long_google_reviews['Text'].apply(lambda x: create_lsa_summary(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_google_reviews['LSA Summary'] = long_google_reviews['LSA Summary'].apply(lambda x: find_empty_summary(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_lsa = long_google_reviews['LSA Summary'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(google_lsa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_lsa_processed = [dc.preprocess(review) for review in google_lsa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_dict = gensim.corpora.Dictionary(google_lsa_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_dict.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_bow_corpus = [google_dict.doc2bow(doc) for doc in google_lsa_processed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, score in sorted(lda_model[google_bow_corpus[10]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, score in sorted(lda_model_tfidf[google_bow_corpus[10]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "vis_train = pyLDAvis.gensim.prepare(topic_model=lda_model, corpus=lsa_corpus, dictionary=topic_dict)\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(vis_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_test = pyLDAvis.gensim.prepare(topic_model=lda_model_tfidf, corpus=google_bow_corpus, dictionary=google_dict)\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(vis_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Do a bag of words model or something else\n",
    "2. Do this for each summary and normal text\n",
    "3. Generate a topic distribution with LDA on both generated summary and normal text\n",
    "4. Evaluate with Kullback-Leibler and Jensen-Shannon divergence or cosine similarity\n",
    "\n",
    "5. create ground truth from BERT model \n",
    "6. compare this to the LSA and Lex Rank summaries with cosine similarity."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Lex and LSA summaries for the google reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(stop_words=\"english\")\n",
    "not_summarised = long_google_reviews.Text.values.tolist()\n",
    "cosine_scores = []\n",
    "for review_a, review_b in zip(google_lsa, not_summarised):\n",
    "\n",
    "    lsa_goole_vec = vectorizer.fit_transform([review_a])\n",
    "    normal_google_vec = vectorizer.transform([review_b])\n",
    "    cosine_sim = cosine_similarity(lsa_goole_vec, normal_google_vec)[0][0]\n",
    "    cosine_scores.append(cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cosine_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_differences = []\n",
    "for i in range(len(not_summarised)):\n",
    "    length_difference = len(not_summarised[i]) - len(google_lsa[i])\n",
    "    length_differences.append(length_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.scatter(cosine_scores, length_differences)\n",
    "fig = plt.figure(num='Summarisation stats')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Cosine Similarity')\n",
    "plt.ylabel('Difference in Length')\n",
    "plt.title('Relationship between Cosine Similarity and Difference in Length')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
